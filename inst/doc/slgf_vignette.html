<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Bayesian Model Selection with SLGF</title>

<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Bayesian Model Selection with SLGF</h1>



<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>The package <code>slgf</code> implements the suspected latent grouping factor (SLGF) methodology of <span class="citation">Metzger and Franck (2019)</span>. In this vignette, we first provide a brief theoretical and mathematical review of the method. Next, through the use of real observational data and a designed experiment, we illustrate the usage of <code>slgf</code> in the context of two common linear model layouts: one-way analysis of variance (ANOVA) and a two-way unreplicated layout. These examples will illustrate the user specification of the models, group-based regression and variance structure, SLGF selection, and regression effect prior specification.</p>
</div>
<div id="functions" class="section level1">
<h1>2 Functions</h1>
<ul>
<li><code>ms.slgf()</code> Computes posterior model probabilities for each user-specified model based on the SLGF grouping methodology</li>
</ul>
<p>This package requires a data frame containing a response variable and at least one categorical factor with three or more levels. In many cases this data frame may also contain additional covariates, either continuous or categorical.</p>
<ul>
<li><p><code>extract.hats()</code> Returns the concentrated maximum likelihood estimates for regression coefficients, variance(s), and <span class="math inline">\(g\)</span> from a user-specified model.</p></li>
<li><p><code>groupings()</code> Computes the unique groupings available for a given <span class="math inline">\(K\)</span>.</p></li>
</ul>
<p>The function <code>ms.slgf</code> requires several inputs to compute and output posterior model probabilities for all models and model classes of interest. The user begins with a data frame containing a continuous response, at least one categorical predictor, and any other covariates of interest. This data frame must not contain column names with the character string <code>group</code>, as this specific string is used by <code>ms.slgf</code> to create the group-based regression effect structure. The user must first identify a suspected latent grouping factor, usually by plotting the data and noting a latent structure within the levels of a categorical predictor as illustrated in Section 3.1. The user indicates, via the arguments <code>response</code> and <code>lgf</code>, character strings corresponding to the response and the suspected latent grouping factor variable names, respectively.</p>
<p>Next the user determines the model classes they wish to evaluate. We note the distinction between these model classes and the <em>R</em> class of a variable. The argument <code>usermodels</code> is a list where each element contains a string of <em>R</em> class <code>formula</code> or <code>character</code>. The user also specifies which classes should also be considered in a heteroscedastic context via the argument <code>het</code>, which provides an indicator <code>1</code> or <code>0</code> corresponding to each model class specified in <code>usermodels</code>. Together the arguments <code>usermodels</code> and <code>het</code> create the full set of model classes considered.</p>
<p>Next the user chooses a prior to place on the regression effects. As described in Section 3.2, <code>prior=&quot;flat&quot;</code> (the default) implements a constant prior and <code>prior=&quot;zs&quot;</code> imposes the Zellner-Siow mixture <span class="math inline">\(g\)</span>-prior.</p>
<p>Finally the user must specify the minimum number of levels of the slgf that can comprise a group, via the argument <code>min.levels</code>, which defaults to <code>1</code>. Because the number of possible grouping schemes increases exponentially with <span class="math inline">\(K\)</span>, the number of levels of the SLGF, the user can reduce the number of candidate models by increasing <code>min.levels</code>, limiting the computational burden. Additionally, when considering data with limited degrees of freedom, increasing <code>min.levels</code> can also ensure estimability of the parametrized <code>usermodels</code>; see Section 4.2 for more detail.</p>
</div>
<div id="analytic-details" class="section level1">
<h1>3 Analytic Details</h1>
<div id="model-specification" class="section level2">
<h2>3.1 Model Specification</h2>
<p>For a thorough review of the model specification see <span class="citation">Metzger and Franck (2019)</span>. We must define a model flexible enough to account for all possible model classes. We begin with the model</p>

<p><span class="math inline">\(\boldsymbol{Y}=X\boldsymbol{\beta}+\boldsymbol{\varepsilon}\)</span>, </p>
<p>where</p>
<ul>
<li><span class="math inline">\(\boldsymbol{Y}\)</span> is an <span class="math inline">\(N\times 1\)</span> vector of continuous observations;</li>
<li><span class="math inline">\(X\)</span> is an <span class="math inline">\(N\times P\)</span> design matrix;</li>
<li><span class="math inline">\(\boldsymbol{\beta}\)</span> is a <span class="math inline">\(P\times 1\)</span> vector of regression effects; and</li>
<li><span class="math inline">\(\boldsymbol{\varepsilon}\)</span> is an <span class="math inline">\(N\times 1\)</span> residual vector where <span class="math inline">\(\boldsymbol{\varepsilon}\sim N(\boldsymbol{0},\, \Sigma)\)</span>.</li>
</ul>
<p>We must augment our notation to account for several additional components: the full slgf with <span class="math inline">\(K\)</span> degrees of freedom or a 2-degree of freedom group effect; interactions with the slgf or group effect; other effects of interest unrelated to the slgf; and potential group-based heteroscedasticity.Thus we let <span class="math inline">\(X=(\boldsymbol{1}^T|W|V|U)\)</span> and <span class="math inline">\(\boldsymbol{\beta}=(\alpha,\boldsymbol{\nu},\boldsymbol{\tau},\boldsymbol{\rho})\)</span> to obtain</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{Y} = \boldsymbol{1}^T \alpha + W\boldsymbol{\nu} + V\boldsymbol{\tau} + U\boldsymbol{\rho} + \boldsymbol{\varepsilon}
\end{equation}\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\boldsymbol{1}^T\)</span> is an <span class="math inline">\(N\times 1\)</span> vector of 1s;</li>
<li><span class="math inline">\(\alpha\)</span> is a scalar intercept common to all models;</li>
<li><span class="math inline">\(\boldsymbol{\nu}\)</span> is the <span class="math inline">\(K\)</span>-dimensional vector of slgf effects;</li>
<li><span class="math inline">\(W\)</span> is the corresponding <span class="math inline">\(K\times N\)</span> design matrix;</li>
<li><span class="math inline">\(\boldsymbol{\tau}\)</span> is the <span class="math inline">\(J\)</span>-dimensional vector of additional effects;</li>
<li><span class="math inline">\(V\)</span> is the corresponding <span class="math inline">\(J\times N\)</span> design matrix;</li>
<li><span class="math inline">\(\boldsymbol{\rho}\)</span> is the <span class="math inline">\(L\)</span>-dimensional vector of slgf-interaction effects; and</li>
<li><span class="math inline">\(U\)</span> is the corresponding <span class="math inline">\(L\times N\)</span> design matrix.</li>
</ul>
<p>Not all linear model classes will incorporate each term; for example, the one-way ANOVA example of Section 4.1 contains only a single categorical predictor so <span class="math inline">\(\bf{\tau}:=\boldsymbol{0}\)</span> and <span class="math inline">\(\bf{\rho}:=\boldsymbol{0}\)</span>. When the slgf is modeled as a group effect, denote this effect as <span class="math inline">\(\tilde{\boldsymbol{\nu}}\)</span>; when there is an interaction involving the group effect, denote it as <span class="math inline">\(\tilde{\boldsymbol{\rho}}\)</span>.</p>
<p>In heteroscedastic contexts, let <span class="math inline">\(\sigma^2_1\)</span> and <span class="math inline">\(\sigma^2_2\)</span> represent the error variances of groups 1 and 2, respectively. Let <span class="math inline">\(\tilde{\Sigma}\)</span> denote the covariance matrix where the <span class="math inline">\(i\)</span>th diagonal element is <span class="math inline">\(\sigma^2_1\)</span> if <span class="math inline">\(y_i\)</span> belongs to group 1, or <span class="math inline">\(\sigma^2_2\)</span> if <span class="math inline">\(y_i\)</span> belongs to group 2.</p>
</div>
<div id="parameter-priors" class="section level2">
<h2>3.2 Parameter Priors</h2>
<p>In the interest of objectivity, we implement noninformative priors on the regression effects and error variance(s). For homoscedastic models,</p>

<p><span class="math inline">\(P(\boldsymbol{\beta},\sigma^2|m)\propto \frac{1}{\sigma^2}\)</span> </p>
<p>and for a heteroscedastic models,  <span class="math inline">\(P(\boldsymbol{\beta},\sigma^2_1, \sigma^2_2|m)\propto \frac{1}{\sigma^2_1\cdot\sigma^2_2}\)</span> </p>
<p>The user implements these priors with the argument <code>prior=&quot;flat&quot;</code>.</p>
<p>However, in contexts with limited data, such as the two-way unreplicated layout of Section 4.2, we recommend the Zellner-Siow mixture <span class="math inline">\(g\)</span>-prior <span class="citation">(Liang et al. 2008)</span>, which reduces the minimal training sample size necessary for the computation of the fractional Bayes factor. For homoscedastic models,</p>

<p><span class="math inline">\(P(\alpha, \sigma^2|m)\propto \frac{1}{\sigma^2}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{-\alpha}|\Sigma,g,m \sim N(\boldsymbol{0},\,g(X^T\Sigma X)^{-1})\)</span>; </p>
<p>for heteroscedastic models,</p>

<p><span class="math inline">\(P(\alpha, \sigma^2_1, \sigma^2_2|m)\propto \frac{1}{\sigma^2_1\cdot\sigma^2_2}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{-\alpha}|\tilde{\Sigma},g,m \sim N(\boldsymbol{0},\,g(X^T\tilde{\Sigma} X)^{-1})\)</span>; </p>
<p>and in both cases,</p>

<p><span class="math inline">\(g\sim \texttt{IG}\big(\frac{1}{2},\, \frac{N}{2}\big)\)</span>. </p>
<p>The user implements these priors with the argument <code>prior=&quot;zs&quot;</code>.</p>
</div>
<div id="fractional-bayes-factors-and-posterior-model-probabilities" class="section level2">
<h2>3.3 Fractional Bayes Factors and Posterior Model Probabilities</h2>
<p>We invoke a fractional Bayes factor approach to compute well-defined posterior model probabilities for each model; for a thorough review and justification see <span class="citation">O’Hagan (1995)</span> and <span class="citation">Metzger and Franck (2019)</span>.</p>
<p>Let <span class="math inline">\(\mathcal{M}\)</span> represent the full set of models under consideration, representing all classes and grouping schemes of interest. Denote <span class="math inline">\(\boldsymbol{\theta}\)</span> as the full set of unknown parameters associated with a model <span class="math inline">\(m\in \mathcal{M}\)</span> and <span class="math inline">\(\pi(\boldsymbol{\theta})\)</span> as the joint prior on these parameters. A fractional Bayes factor is a ratio of two fractional marginal model probabilites, where a fractional marginal likelihood is defined as</p>

<p><span class="math inline">\(q^b(\boldsymbol{Y}|\boldsymbol{\theta})=\frac{\int P(\boldsymbol{Y}|\boldsymbol{\theta},m)\pi(\boldsymbol{\theta})d\boldsymbol{\theta}}{\int P(\boldsymbol{Y}|\boldsymbol{\theta},m)^b\pi(\boldsymbol{\theta})d\boldsymbol{\theta}}\)</span> </p>
<p>for a some fractional exponent <span class="math inline">\(b\)</span>. We exclusively implement <span class="math inline">\(b=\frac{m_0}{N}\)</span> where <span class="math inline">\(m_0\)</span> is the minimal training sample size required for <span class="math inline">\(P(\boldsymbol{Y}|m)\)</span> to be a proper distribution.</p>
<p>Thus <code>slgf</code> must approximate the integrals <span class="math inline">\(\int P(\boldsymbol{Y}|\boldsymbol{\theta},m)\pi(\boldsymbol{\theta})d\boldsymbol{\theta}\)</span> and <span class="math inline">\(\int P(\boldsymbol{Y}|\boldsymbol{\theta},m)^b\pi(\boldsymbol{\theta})d\boldsymbol{\theta}\)</span> for all <span class="math inline">\(m\in \mathcal{M}\)</span>. In the case of noninformative regression priors, <span class="math inline">\(\boldsymbol{\beta}\)</span> is integrated analytically, and <span class="math inline">\(\sigma^2\)</span> or <span class="math inline">\(\sigma^2_1, \sigma^2_2\)</span> are integrated using a Laplace approximation after a log-variance transformation. In the Zellner-Siow mixture <span class="math inline">\(g\)</span>-prior case, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{-\alpha}\)</span> are integrated analytically, and <span class="math inline">\(\sigma^2\)</span> or <span class="math inline">\(\sigma^2_1, \sigma^2_2\)</span> and <span class="math inline">\(g\)</span> are again integrated using a Laplace approximation with a log-variance transformation. Let <span class="math inline">\(\boldsymbol{\tilde{\theta}}\)</span> represent the set of unknown parameters after the regression effects <span class="math inline">\(\boldsymbol{\beta}\)</span> have been integrated out. Then for dimensionality <span class="math inline">\(d=2\)</span> in the noninformative prior case and <span class="math inline">\(d=3\)</span> in the Zellner-Siow mixture <span class="math inline">\(g\)</span>-prior case,</p>

<p><span class="math inline">\(\log\big(\int P(\boldsymbol{Y}|\boldsymbol{\tilde{\theta}},m)\pi(\boldsymbol{\tilde{\theta}})d\boldsymbol{\tilde{\theta}}\big)\approx \frac{d}{2}\log(2\pi)-\frac{1}{2}\log|-H^{\star}|+\log(P(\boldsymbol{Y}|\boldsymbol{\tilde{\theta}}^{\star},m))\)</span> </p>
<p>where <span class="math inline">\(\boldsymbol{\tilde{\theta}}^{\star}\)</span> is the mode of <span class="math inline">\(P(\boldsymbol{Y}|\boldsymbol{\tilde{\theta}},m)\pi(\boldsymbol{\tilde{\theta}})\)</span> and <span class="math inline">\(H^{\star}\)</span> is the Hessian matrix evaluated at <span class="math inline">\(\boldsymbol{\tilde{\theta}}^{\star}\)</span>. These values are computed with the functions <code>optim</code> and <code>numDeriv::hessian</code>, respectively. We make a similar computation for <span class="math inline">\(\int P(\boldsymbol{Y}|\boldsymbol{\tilde{\theta}},m)^b\pi(\boldsymbol{\tilde{\theta}})d\boldsymbol{\tilde{\theta}}\)</span> to compute the fractional marginal model probability <span class="math inline">\(q^b(\boldsymbol{Y}|\boldsymbol{\theta})\)</span> for all <span class="math inline">\(m\in \mathcal{M}\)</span>, well defined for both homoscedastic and heteroscedastic models. Once log-fractional marginal likelihoods have been computed for all models, we subtract the maximum from this set so that the set of log-fractional marginal likelihoods has been rescaled to have a maximum of 0. Each value is exponentiated to obtain a set of fractional marginal likelihoods with maximum 1 to avoid numerical underflow when computing posterior model probabilities.</p>
<p>Model priors are imposed uniformly prior by model class, and for classes containing multiple models, the prior on each class is uniformly divided among the models it contains.</p>
<p>We finally compute posterior model probabilities for each model:</p>

<p><span class="math inline">\(P(m^{\prime}|\boldsymbol{Y})=\frac{P(\boldsymbol{Y}|m^{\prime})P(m^{\prime})}{\underset{\mathcal{M}}{\sum}P(\boldsymbol{Y}|m)P(m)}\)</span> </p>
</div>
</div>
<div id="examples" class="section level1">
<h1>4 Examples</h1>
<div id="one-way-analysis-of-variance-anova" class="section level2">
<h2>4.1 One-way Analysis of Variance (ANOVA)</h2>
<p>First consider the data of <span class="citation">OBrien and Heft (1995)</span>, who studied olfactory function by age (<span class="math inline">\(y\)</span>-axis), where age was divided into five categories (<span class="math inline">\(x\)</span>-axis). Load the dataset:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">data</span>(smell)</span></code></pre></div>
<p>A simple boxplot suggests potential heteroscedasticity, with latent grouping structure 1,2,3:4,5. We propose the alternative notation {1,2,3}{4,5} to avoid ambiguity with the “<code>:</code>” symbol used with strings of class <code>formula</code> in R.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">boxplot</span>(smell<span class="op">$</span>olf <span class="op">~</span><span class="st"> </span>smell<span class="op">$</span>agecat, <span class="dt">pch =</span> <span class="dv">16</span>, <span class="dt">xlab =</span> <span class="st">&quot;Age Category&quot;</span>, </span>
<span id="cb2-2"><a href="#cb2-2"></a>    <span class="dt">ylab =</span> <span class="st">&quot;Olfactory Score&quot;</span>, <span class="dt">xaxt =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;gray30&quot;</span>, <span class="st">&quot;gray30&quot;</span>, </span>
<span id="cb2-3"><a href="#cb2-3"></a>        <span class="st">&quot;gray30&quot;</span>, <span class="st">&quot;white&quot;</span>, <span class="st">&quot;white&quot;</span>), <span class="dt">border =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;black&quot;</span>, </span>
<span id="cb2-4"><a href="#cb2-4"></a>        <span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">main =</span> <span class="st">&quot;O&#39;Brien and Heft (1995) Smell Data&quot;</span>)</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="kw">axis</span>(<span class="dv">1</span>, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;1</span><span class="ch">\n</span><span class="st">(n=38)&quot;</span>, <span class="st">&quot;2</span><span class="ch">\n</span><span class="st">(n=35)&quot;</span>, <span class="st">&quot;3</span><span class="ch">\n</span><span class="st">(n=21)&quot;</span>, <span class="st">&quot;4</span><span class="ch">\n</span><span class="st">(n=43)&quot;</span>, </span>
<span id="cb2-6"><a href="#cb2-6"></a>    <span class="st">&quot;5</span><span class="ch">\n</span><span class="st">(n=42)&quot;</span>), <span class="dt">at =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="dt">lwd.tick =</span> <span class="dv">0</span>)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="data:image/png;base64,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" alt="O&#39;Brien and Heft (1995) studied olfactory function by age ($y$-axis), where age was divided into five categories ($x$-axis). The data suggests potential heteroscedasticity, with latent grouping structure {1,2,3}{4,5}." />
<p class="caption">
O’Brien and Heft (1995) studied olfactory function by age (<span class="math inline">\(y\)</span>-axis), where age was divided into five categories (<span class="math inline">\(x\)</span>-axis). The data suggests potential heteroscedasticity, with latent grouping structure {1,2,3}{4,5}.
</p>
</div>
<p>We thus consider <code>agecat</code> as the suspected latent grouping factor. The apparent latent grouping scheme we observe is denoted {1,2,3}{4,5} (or equivalently, {4,5}{1,2,3}), but all possible grouping schemes are considered. The means may also differ by level, but this is more difficult to distinguish by the plot. Thus we first consider the following model and heteroscedasticity structures:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>smell.models &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;olf~1&quot;</span>, <span class="st">&quot;olf~agecat&quot;</span>, <span class="st">&quot;olf~group&quot;</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a>smell.het &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span></code></pre></div>
<p>By specifying <code>smell.models</code> and <code>smell.het</code> as done above, we consider the third model specified with group-based heteroscedasticity. This elicits four model classes: a homoscedastic global mean, homoscedastic age level means, homoscedastic group-based means, and group-based means with group-based heteroscedasticity. Finally we note that with a relatively large sample size, we prefer the use of noninformative priors via <code>prior=&quot;flat&quot;</code>, and we specify <code>min.levels=1</code>, as we have no prior information on the number of levels of <code>agecat</code> that may be grouped together and we wish to consider a comprehensive set of candidate models. With the model specification list argument <code>usermodels</code> and the heteroscedasticity vector argument <code>het</code>, the number of unique classes can be obtained as <code>length(usermodels)+sum(het)</code>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a>smell.out &lt;-<span class="st"> </span><span class="kw">ms.slgf</span>(<span class="dt">dataf=</span>smell, <span class="dt">response=</span><span class="st">&quot;olf&quot;</span>, <span class="dt">lgf=</span><span class="st">&quot;agecat&quot;</span>, <span class="dt">usermodels=</span>smell.models, </span>
<span id="cb4-2"><a href="#cb4-2"></a>                     <span class="dt">prior=</span><span class="st">&quot;flat&quot;</span>, <span class="dt">het=</span>smell.het, <span class="dt">min.levels=</span><span class="dv">1</span>)</span></code></pre></div>
<p>Note by specifying the argument <code>min.levels=1</code>, we consider all possible grouping schemes containing at least one level of the SLGF. We could specify <code>min.levels=2</code> to consider a smaller model space with at least two levels per group, but <code>min.levels=3</code> or greater is not possible with five levels of the SLGF. The output <code>smell.out</code> is a list of class <code>slgf</code>, with six elements when <code>prior=&quot;flat&quot;</code> and seven when <code>prior=&quot;zs&quot;</code>; see the help file for full details.</p>
<p>We summarize the five most probable models of 32 considered:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a>smell.out<span class="op">$</span>results[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,<span class="dv">6</span>,<span class="dv">11</span>)]</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co">#&gt;        Model       Scheme Variance   Fmodprob               Class</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="co">#&gt; 1  olf~group {4,5}{1,2,3} Heterosk 0.99987407 olf~group, Heterosk</span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="co">#&gt; 2  olf~group {1,2}{3,4,5} Heterosk 0.00012589 olf~group, Heterosk</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="co">#&gt; 3 olf~agecat         None   Homosk 0.00000003  olf~agecat, Homosk</span></span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="co">#&gt; 4  olf~group {5}{1,2,3,4} Heterosk 0.00000000 olf~group, Heterosk</span></span>
<span id="cb5-7"><a href="#cb5-7"></a><span class="co">#&gt; 5  olf~group {4,5}{1,2,3}   Homosk 0.00000000   olf~group, Homosk</span></span></code></pre></div>
<p>We strongly favor the model with group-based mean effects and variances via scheme {4,5}{1,2,3}.</p>
<p>The function <code>extract.hats</code> provides the estimates for the coefficient(s) and variance(s) for a given <code>model.index</code>, as well as <span class="math inline">\(g\)</span> if <code>prior=&quot;zs&quot;</code>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>smell.hats &lt;-<span class="st"> </span><span class="kw">extract.hats</span>(smell.out, <span class="dt">model.index=</span><span class="dv">1</span>)</span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="kw">print</span>(smell.hats<span class="op">$</span><span class="st">`</span><span class="dt">sigsq.{4,5}</span><span class="st">`</span>)</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="co">#&gt; [1] 0.01211023</span></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="kw">print</span>(smell.hats<span class="op">$</span><span class="st">`</span><span class="dt">sigsq.{1,2,3}</span><span class="st">`</span>)</span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="co">#&gt; [1] 0.05868753</span></span></code></pre></div>
<p>That is, we compute <span class="math inline">\(\hat{\sigma}^2_{\text{1,2,3}}=\)</span> 0.05869 and <span class="math inline">\(\hat{\sigma}^2_{\text{4,5}}=\)</span> 0.01211. Let us also consider the case where <code>het=c(1,1,1)</code>; that is, we include two additional classes: group-based variances and a single global mean, and group-based variances with means by <code>agecat</code>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a>smell.out &lt;-<span class="st"> </span><span class="kw">ms.slgf</span>(<span class="dt">dataf=</span>smell, <span class="dt">response=</span><span class="st">&quot;olf&quot;</span>, <span class="dt">lgf=</span><span class="st">&quot;agecat&quot;</span>, </span>
<span id="cb7-2"><a href="#cb7-2"></a>                     <span class="dt">usermodels=</span>smell.models, <span class="dt">prior=</span><span class="st">&quot;flat&quot;</span>, </span>
<span id="cb7-3"><a href="#cb7-3"></a>                     <span class="dt">het=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">min.levels=</span><span class="dv">1</span>)</span>
<span id="cb7-4"><a href="#cb7-4"></a></span>
<span id="cb7-5"><a href="#cb7-5"></a>smell.out<span class="op">$</span>results[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,<span class="dv">6</span>,<span class="dv">11</span>)]</span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="co">#&gt;        Model       Scheme Variance   Fmodprob                Class</span></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="co">#&gt; 1  olf~group {4,5}{1,2,3} Heterosk 0.54204570  olf~group, Heterosk</span></span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="co">#&gt; 2 olf~agecat {4,5}{1,2,3} Heterosk 0.44946817 olf~agecat, Heterosk</span></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="co">#&gt; 3 olf~agecat {1,2}{3,4,5} Heterosk 0.00840126 olf~agecat, Heterosk</span></span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="co">#&gt; 4  olf~group {1,2}{3,4,5} Heterosk 0.00007605  olf~group, Heterosk</span></span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="co">#&gt; 5 olf~agecat {1,3}{2,4,5} Heterosk 0.00000566 olf~agecat, Heterosk</span></span></code></pre></div>
<p>Now the most probable models are a bit less conclusive, as the distinct category-means model with scheme {4,5}{1,2,3} group-based heteroscedasticity accounts for a meaningful amount of posterior model probability. We can easily summarize the scheme and class probabilities, which strongly favor scheme {4,5}{1,2,3} and moderately favor the group-based means and variances model class:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>smell.out<span class="op">$</span>scheme.Probs</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="co">#&gt;              Scheme.Prob</span></span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="co">#&gt; {4,5}{1,2,3}  0.99151391</span></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="co">#&gt; {1,2}{3,4,5}  0.00847731</span></span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="co">#&gt; {1,3}{2,4,5}  0.00000566</span></span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="co">#&gt; {2,3}{1,4,5}  0.00000219</span></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="co">#&gt; {1}{2,3,4,5}  0.00000047</span></span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="co">#&gt; {5}{1,2,3,4}  0.00000025</span></span>
<span id="cb8-9"><a href="#cb8-9"></a><span class="co">#&gt; {2}{1,3,4,5}  0.00000018</span></span>
<span id="cb8-10"><a href="#cb8-10"></a><span class="co">#&gt; None          0.00000002</span></span>
<span id="cb8-11"><a href="#cb8-11"></a><span class="co">#&gt; {1,4}{2,3,5}  0.00000000</span></span>
<span id="cb8-12"><a href="#cb8-12"></a><span class="co">#&gt; {1,5}{2,3,4}  0.00000000</span></span>
<span id="cb8-13"><a href="#cb8-13"></a><span class="co">#&gt; {2,4}{1,3,5}  0.00000000</span></span>
<span id="cb8-14"><a href="#cb8-14"></a><span class="co">#&gt; {2,5}{1,3,4}  0.00000000</span></span>
<span id="cb8-15"><a href="#cb8-15"></a><span class="co">#&gt; {3,4}{1,2,5}  0.00000000</span></span>
<span id="cb8-16"><a href="#cb8-16"></a><span class="co">#&gt; {3,5}{1,2,4}  0.00000000</span></span>
<span id="cb8-17"><a href="#cb8-17"></a><span class="co">#&gt; {3}{1,2,4,5}  0.00000000</span></span>
<span id="cb8-18"><a href="#cb8-18"></a><span class="co">#&gt; {4}{1,2,3,5}  0.00000000</span></span>
<span id="cb8-19"><a href="#cb8-19"></a>smell.out<span class="op">$</span>class.Probs</span>
<span id="cb8-20"><a href="#cb8-20"></a><span class="co">#&gt;                      Class.Prob</span></span>
<span id="cb8-21"><a href="#cb8-21"></a><span class="co">#&gt; olf~group, Heterosk  0.54212175</span></span>
<span id="cb8-22"><a href="#cb8-22"></a><span class="co">#&gt; olf~agecat, Heterosk 0.45787818</span></span>
<span id="cb8-23"><a href="#cb8-23"></a><span class="co">#&gt; olf~1, Heterosk      0.00000004</span></span>
<span id="cb8-24"><a href="#cb8-24"></a><span class="co">#&gt; olf~agecat, Homosk   0.00000002</span></span>
<span id="cb8-25"><a href="#cb8-25"></a><span class="co">#&gt; olf~1, Homosk        0.00000000</span></span>
<span id="cb8-26"><a href="#cb8-26"></a><span class="co">#&gt; olf~group, Homosk    0.00000000</span></span></code></pre></div>
</div>
<div id="unreplicated-two-way-layouts" class="section level2">
<h2>4.3 Unreplicated Two-way Layouts</h2>
<p>Next we analyze a two-way unreplicated layout. Consider the data analyzed by <span class="citation">Franck, Nielsen, and Osborne (2013)</span>, where six dogs with lymphoma were studied. Two individual samples were taken from healthy and tumor tissue within each dog, and the copy number variation was measured for each sample. We arrange dogs into rows and tissue types into columns of a two-way layout. We first plot the data to determine whether a latent grouping structure underlies the data:</p>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>We strongly suspect that dogs 1, 2, and 5 behave distinctly from dogs 3, 4, and 6. The telltale non-parallel lines suggest an underlying interaction, but with only a single observation in each cell, we lack the degrees of freedom to fit a standard row by column interaction term. Instead, we let <code>dog</code> represent the SLGF, exclude the column effect, and parametrize a group-by-column interaction term, isomorphic to fitting distinct column effects by group. Thus we consider four reasonable model classes: a dog and tissue effect, a dog and tissue-by-column interaction, and the heteroscedastic counterparts of each class. We accomplish this with the arguments <code>usermodels=list(&quot;gene~dog+tissue&quot;, &quot;gene~dog+group:tissue&quot;)</code> and <code>het=c(1,1)</code>. Additionally, we must specify <code>min.levels=2</code> or <code>min.levels=3</code> to ensure sufficient degrees of freedom to estimate the <code>group:col</code> effect. Here we consider <code>min.levels=2</code> in the interest of assessing a more complete set of candidate models.</p>
<p>Because of the limited amount of data, our choice of prior is more impactful in this case. We impose <code>prior=&quot;zs&quot;</code> to utilize the Zellner-Siow mixture <span class="math inline">\(g\)</span>-prior, as the fractional Bayes factor exponent would require a prohibitively high proportion of the data for model training.</p>
<p>We first put the two-way layout into a <code>data.frame</code> format compatible with the <code>slgf</code> function, and then implement this approach.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>lymphoma.tall &lt;-<span class="st"> </span><span class="kw">maketall</span>(lymphoma)</span>
<span id="cb9-2"><a href="#cb9-2"></a>lymphoma.tall &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;gene&quot;</span>=lymphoma.tall[,<span class="dv">1</span>], <span class="st">&quot;dog&quot;</span>=lymphoma.tall[,<span class="dv">2</span>], </span>
<span id="cb9-3"><a href="#cb9-3"></a>                            <span class="st">&quot;tissue&quot;</span>=lymphoma.tall[,<span class="dv">3</span>])</span>
<span id="cb9-4"><a href="#cb9-4"></a></span>
<span id="cb9-5"><a href="#cb9-5"></a>lymphoma.models &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;gene~dog+tissue&quot;</span>, <span class="st">&quot;gene~dog+group:tissue&quot;</span>)</span>
<span id="cb9-6"><a href="#cb9-6"></a>lymphoma.out &lt;-<span class="st"> </span><span class="kw">ms.slgf</span>(<span class="dt">dataf=</span>lymphoma.tall, <span class="dt">response=</span><span class="st">&quot;gene&quot;</span>, <span class="dt">lgf=</span><span class="st">&quot;dog&quot;</span>, </span>
<span id="cb9-7"><a href="#cb9-7"></a>                        <span class="dt">usermodels=</span>lymphoma.models, <span class="dt">prior=</span><span class="st">&quot;zs&quot;</span>, </span>
<span id="cb9-8"><a href="#cb9-8"></a>                        <span class="dt">het=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">min.levels=</span><span class="dv">2</span>)</span></code></pre></div>
<p>Note the <code>:</code> operator in the <code>usermodels</code> syntax, which does not automatically include the main effects <code>group</code> and <code>tissue</code> which are not both estimable. As expected, we conclude with high probability that scheme {1,2,5}{3,4,6} underlies the data. The five most probable models are given by:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>lymphoma.out<span class="op">$</span>results[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,<span class="dv">6</span>)]</span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="co">#&gt;                   Model         Scheme Variance   Fmodprob</span></span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="co">#&gt; 1 gene~dog+group:tissue {1,2,5}{3,4,6}   Homosk 0.73643491</span></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="co">#&gt; 2 gene~dog+group:tissue {1,2,5}{3,4,6} Heterosk 0.24833051</span></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="co">#&gt; 3       gene~dog+tissue           None   Homosk 0.00311082</span></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="co">#&gt; 4 gene~dog+group:tissue {1,2}{3,4,5,6} Heterosk 0.00211760</span></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="co">#&gt; 5       gene~dog+tissue {1,2,5}{3,4,6} Heterosk 0.00109052</span></span></code></pre></div>
<p>while the class and five highest scheme probailities are</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>lymphoma.out<span class="op">$</span>class.Probs</span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="co">#&gt;                                 Class.Prob</span></span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="co">#&gt; gene~dog+group:tissue, Homosk   0.74081898</span></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="co">#&gt; gene~dog+group:tissue, Heterosk 0.25326343</span></span>
<span id="cb11-5"><a href="#cb11-5"></a><span class="co">#&gt; gene~dog+tissue, Homosk         0.00311082</span></span>
<span id="cb11-6"><a href="#cb11-6"></a><span class="co">#&gt; gene~dog+tissue, Heterosk       0.00280677</span></span>
<span id="cb11-7"><a href="#cb11-7"></a><span class="kw">head</span>(lymphoma.out<span class="op">$</span>scheme.Probs, <span class="dv">5</span>)</span>
<span id="cb11-8"><a href="#cb11-8"></a><span class="co">#&gt;                Scheme.Prob</span></span>
<span id="cb11-9"><a href="#cb11-9"></a><span class="co">#&gt; {1,2,5}{3,4,6}  0.98585594</span></span>
<span id="cb11-10"><a href="#cb11-10"></a><span class="co">#&gt; None            0.00311082</span></span>
<span id="cb11-11"><a href="#cb11-11"></a><span class="co">#&gt; {1,2}{3,4,5,6}  0.00288222</span></span>
<span id="cb11-12"><a href="#cb11-12"></a><span class="co">#&gt; {1,5}{2,3,4,6}  0.00145899</span></span>
<span id="cb11-13"><a href="#cb11-13"></a><span class="co">#&gt; {3,6}{1,2,4,5}  0.00081783</span></span></code></pre></div>
<p>The <code>group.datafs</code> element of <code>lymphoma.out</code> contains <code>data.frames</code> associated with each model and grouping scheme. We first determine which element of <code>lymphoma.out$group.datafs</code> contains the <code>data.frame</code> of interest via the column <code>dataf.Index</code>:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>lymphoma.out<span class="op">$</span>results[<span class="dv">1</span>,<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,<span class="dv">6</span>,<span class="dv">8</span>)]</span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="co">#&gt;                   Model         Scheme Variance  Fmodprob dataf.Index</span></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="co">#&gt; 1 gene~dog+group:tissue {1,2,5}{3,4,6}   Homosk 0.7364349          18</span></span></code></pre></div>
<p>This tells us that element 18 of <code>lymphoma.out$group.datafs</code> contains the <code>data.frame</code> with the {1,2,5}{3,4,6} group effect:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>lymphoma.out<span class="op">$</span>group.datafs[[<span class="dv">18</span>]]</span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="co">#&gt;      gene dog tissue group</span></span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="co">#&gt; 1  9.3278   1      1 1,2,5</span></span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="co">#&gt; 2  9.2168   1      2 1,2,5</span></span>
<span id="cb13-5"><a href="#cb13-5"></a><span class="co">#&gt; 3  9.5108   2      1 1,2,5</span></span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="co">#&gt; 4  9.3942   2      2 1,2,5</span></span>
<span id="cb13-7"><a href="#cb13-7"></a><span class="co">#&gt; 5  8.7535   3      1 3,4,6</span></span>
<span id="cb13-8"><a href="#cb13-8"></a><span class="co">#&gt; 6  9.4158   3      2 3,4,6</span></span>
<span id="cb13-9"><a href="#cb13-9"></a><span class="co">#&gt; 7  8.6372   4      1 3,4,6</span></span>
<span id="cb13-10"><a href="#cb13-10"></a><span class="co">#&gt; 8  9.2480   4      2 3,4,6</span></span>
<span id="cb13-11"><a href="#cb13-11"></a><span class="co">#&gt; 9  9.4981   5      1 1,2,5</span></span>
<span id="cb13-12"><a href="#cb13-12"></a><span class="co">#&gt; 10 9.4626   5      2 1,2,5</span></span>
<span id="cb13-13"><a href="#cb13-13"></a><span class="co">#&gt; 11 8.7322   6      1 3,4,6</span></span>
<span id="cb13-14"><a href="#cb13-14"></a><span class="co">#&gt; 12 9.3439   6      2 3,4,6</span></span></code></pre></div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-franckdogs">
<p>Franck, Christopher T., Dahlia M. Nielsen, and Jason A. Osborne. 2013. “A Method for Detecting Hidden Additivity in Two-Factor Unreplicated Experiments.” <em>Computational Statistics &amp; Data Analysis</em> 67 (Supplement C): 95–104. <a href="https://doi.org/https://doi.org/10.1016/j.csda.2013.05.002">https://doi.org/https://doi.org/10.1016/j.csda.2013.05.002</a>.</p>
</div>
<div id="ref-Liangetal">
<p>Liang, Feng, Rui Paulo, German Molina, Merlise A Clyde, and Jim O Berger. 2008. “Mixtures of G Priors for Bayesian Variable Selection.” <em>Journal of the American Statistical Association</em> 103 (481): 410–23. <a href="https://doi.org/10.1198/016214507000001337">https://doi.org/10.1198/016214507000001337</a>.</p>
</div>
<div id="ref-metzger2019">
<p>Metzger, Thomas A., and Christopher T. Franck. 2019. “Detection of latent heteroscedasticity and group-based regression effects in linear models via Bayesian model selection.” <em>arXiv E-Prints</em>, March.</p>
</div>
<div id="ref-ObrienHeft">
<p>OBrien, R. G., and M. W. Heft. 1995. “New Discrimination Indexes and Models for Studying Sensory Functioning in Aging.” <em>Journal of Applied Statistics</em> 22: 9–27.</p>
</div>
<div id="ref-OHaganfbfs">
<p>O’Hagan, Anthony. 1995. “Fractional Bayes Factors for Model Comparison.” <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 57 (1): 99–138. <a href="http://www.jstor.org/stable/2346088">http://www.jstor.org/stable/2346088</a>.</p>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
